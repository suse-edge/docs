[#day2-k8s-upgrade]
== Kubernetes version upgrade
:experimental:

ifdef::env-github[]
:imagesdir: ../images/
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:toc: auto

[IMPORTANT]
====
This section covers Kubernetes upgrades for downstream clusters that have *NOT* been created through a <<components-rancher,Rancher>> instance. For information on how to upgrade the Kubernetes version of `Rancher` created clusters, see link:https://ranchermanager.docs.rancher.com/v2.8/getting-started/installation-and-upgrade/upgrade-and-roll-back-kubernetes#upgrading-the-kubernetes-version[Upgrading and Rolling Back Kubernetes].
====

=== Components

This section covers the general components that are used to achieve a Kubernetes version upgrade:

* <<components-rancher,Rancher>> - Located on the <<day2-mgmt-cluster,Rancher Management Cluster>>; responsible for the downstream cluster management. *For use-cases where you want to utilise <<components-fleet,Fleet>> without Rancher, you can skip the Rancher component all together.*

* <<components-fleet,Fleet>> - Deployed by the `Rancher` component by default; responsible for muti-cluster resource deployment. Alternatively, if you are not using `Rancher`, `Fleet` can be deployed as a standalone component. For more information, see link:https://fleet.rancher.io/installation[Installation Details].

* link:https://github.com/rancher/system-upgrade-controller[system-upgrade-controller] (*SUC*) - Located on each downstream cluster; responsible for executing tasks on specified nodes based on configuration data provided throguh a custom resource, called a `Plan`. For information on how to setup *SUC*, see <<day2-suc-deployment-guide>>

* link:https://github.com/rancher/rke2-upgrade/tree/master[rke2-upgrade] - Used through a SUC `Plan` resource located on each downstream cluster; responsible for upgrading the RKE2 version that a single cluster node is running.

* link:https://github.com/k3s-io/k3s-upgrade[k3s-upgrade] - Used through a SUC `Plan` resource located on each downstream cluster; responsible for upgrading the K3s version that a single cluster node is running.

=== Requirements

. *Backup your Kubernetes distribution:*

.. For *imported RKE2 clusters*, see the link:https://docs.rke2.io/backup_restore[RKE2 Backup and Restore] documentation.

.. For *imported K3s clusters*, see the link:https://docs.k3s.io/datastore/backup-restore[K3s Backup and Restore] documentation.

. *Make sure that SUC Plan tolerations match node tolerations* - If your Kubernetes cluster nodes have custom *taints*, make sure to add link:https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/[tolerations] for those taints in the *SUC Plans*. By default *SUC Plans* have tolerations only for *control-plane* nodes. Default tolerations include: 

* _CriticalAddonsOnly=true:NoExecute_

* _node-role.kubernetes.io/control-plane:NoSchedule_

* _node-role.kubernetes.io/etcd:NoExecute_
+
[NOTE]
====
Any additional tolerations must be added under the `.spec.tolerations` section of each Plan. *SUC Plans* related to the Kubernetes version upgrade can be found in the link:https://github.com/ipetrov117/fleet-examples[suse-edge/fleet-examples] repository under:

* For *RKE2* - `fleets/day2/system-upgrade-controller-plans/rke2-upgrade`
* For *K3s*  - `fleets/day2/system-upgrade-controller-plans/k3s-upgrade`

*Make sure you use the Plans from a valid repository link:https://github.com/ipetrov117/fleet-examples/releases[release] tag.*

An example of defining custom tolerations for the RKE2 *control-plane* SUC Plan, would look like this:
[,yaml]
----
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: rke2-plan-control-plane
spec:
  ...
  tolerations:
  # default tolerations
  - key: "CriticalAddonsOnly"
    operator: "Equal"
    value: "true"
    effect: "NoExecute"
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Equal"
    effect: "NoSchedule"
  - key: "node-role.kubernetes.io/etcd"
    operator: "Equal"
    effect: "NoExecute"
  # custom toleration
  - key: "foo"
    operator: "Equal"
    value: "bar"
    effect: "NoSchedule"
...
----
====

=== Upgrade procedure
[NOTE]
====
This section assumes you will be deploying *SUC Plans* using <<components-fleet,Fleet>>. If you intend to deploy the *SUC Plan* using a different approach, refer to <<k8s-upgrade-suc-plan-deployment-third-party>>.
====

The `Kubernetes version upgrade procedure` revolves around deploying *SUC Plans* to downstream clusters. These plans hold information that instructs the *SUC* on how to perform the upgrade on *each* of the downstream cluster nodes. For information regarding the structure of a *SUC Plan*, refer to the https://github.com/rancher/system-upgrade-controller?tab=readme-ov-file#example-plans[upstream] documentation.

Deployment orchestration for these *Plans* is done by using either a *GitRepo* or a *Bundle* resource. 

A *GitRepo* resource represents a Git repository from which *Fleet* creates *Bundles*. While *Bundles* are resources that hold the *raw* Kubernetes resources that will be deployed on the targeted cluster. For more information, refer to the https://fleet.rancher.io/gitrepo-add[GitRepo] and https://fleet.rancher.io/bundle-add[Bundle] documentations.

Whether to use the *GitRepo* or *Bundle* resource depends on your use-case, refer to the <<k8s-upgrade-determine-use-case>> section for more information.

For a full overview of what happens during the _update procedure_, refer to the <<k8s-version-upgrade-overview>> section.

[#k8s-upgrade-determine-use-case]
==== Determine use-case

This section aims at helping users determine which Fleet resource (*GitRepo* or *Bundle*) is more suited to deploy the `Kubernetes version upgrade SUC Plans` based on the environment's use-case.

===== GitRepo

*GitRepo* resources are normally used to deploy *SUC Plans* on *non air-gapped* environments that utilise a _Fleet GitOps_ approach.

Alternatively, *GitRepo* resources can also be used to deploy *SUC Plans* on *air-gapped* environments, *if you mirror your repository setup through a local git server*.

The Edge team maintains ready to use *GitRepo* resource for the *SUC Plans* related to the Kubernetes version upgrade in our link:https://github.com/ipetrov117/fleet-examples[suse-edge/fleet-examples] repository under:

* For *RKE2* - `gitrepos/day2/rke2-upgrade-gitrepo.yaml`

* For *K3s*  - `gitrepos/day2/k3s-upgrade-gitrepo.yaml`

[NOTE]
====
If your use-case does not require any additional custom configurations over the *GitRepo* resource, or any related to the resource `fleets` (e.g. the underlying upgrade Plan resources), you can directly use the *GitRepo* from the `suse-edge/fleet-examples` repository.
====

[IMPORTANT]
====
If using the `suse-edge/fleet-examples` repository, make sure you are using the *GitRepo* resource from a dedicated link:https://github.com/ipetrov117/fleet-examples/releases[release] tag.
====

For information on how to deploy the *Kubernetes version upgrade SUC Plans* using Fleet's *GitRepo* resource, refer to the <<k8s-upgrade-suc-plan-deployment-git-repo>> section.

===== Bundle

*Bundle* resources are normally used to deploy *SUC Plans* on *air-gapped* environments that do not use some form of _local GitOps_ procedure (e.g. a *local git server*).

Alternatively, if your use-case does not allow for a _GitOps_ workflow, *Bundle* resources could also be used to deploy *SUC Plans* on *non air-gapped* environments. 

The Edge team maintains ready to use *Bundle* resource for the *SUC Plans* related to the Kubernetes version upgrade in our link:https://github.com/ipetrov117/fleet-examples[suse-edge/fleet-examples] repository under:

* For *RKE2* - `bundles/day2/system-upgrade-controller-plans/rke2-upgrade/plan-bundle.yaml`

* For *K3s*  - `bundles/day2/system-upgrade-controller-plans/k3s-upgrade/plan-bundle.yaml`

[NOTE]
====
If your use-case does not require any additional custom configurations over the *Bundle* resource, you can directly use it from the `suse-edge/fleet-examples` repository.
====

[IMPORTANT]
====
If using the `suse-edge/fleet-examples` repository, make sure you are using the *Bundle* resource from a dedicated link:https://github.com/ipetrov117/fleet-examples/releases[release] tag.
====

For information on how to deploy the *Kubernetes version upgrade SUC Plans* using Fleet's *Bundle* resource, refer to the <<k8s-upgrade-suc-plan-deployment-bundle>> section.

[#k8s-version-upgrade-overview]
==== Overview

This section aims to describe the full workflow that the *_Kubernetes version upgrade process_* goes throught from start to finish.

.Kubernetes version upgrade workflow
image::day2_k8s_version_upgrade_diagram.png[]

Kubernetes version upgrade steps:

. Based on his use-case, the user determines whether to use a *GitRepo* or a *Bundle* resource for the deployment of the `Kubernetes upgrade SUC Plans` to the desired downstream clusters. For information on how to map a *GitRepo/Bundle* to a specific set of downstream clusters, see https://fleet.rancher.io/gitrepo-targets[Mapping to Downstream Clusters].

.. If you are unsure whether you should use a *GitRepo* or a *Bundle* resource for the *SUC Plan* deployment, refer to <<k8s-upgrade-determine-use-case>>.

.. For *GitRepo/Bundle* configuration options, refer to <<k8s-upgrade-suc-plan-deployment-git-repo>> or <<k8s-upgrade-suc-plan-deployment-bundle>>.

. The user deploys the configured *GitRepo/Bundle* resource to the `fleet-default` namespace in his <<day2-mgmt-cluster,Rancher Management Cluster>>. This is done either *manually* or thorugh the *Rancher UI* if such is available.

. <<components-fleet,Fleet>> constantly monitors the `fleet-default` namespace and immediately detects the newly deployed *GitRepo/Bundle* resource. For more information regarding what namespaces does Fleet monitor, refer to Fleet's https://fleet.rancher.io/namespaces[Namespaces] documentation.

. If the user has deployed a *GitRepo* resource, `Fleet` will reconcile the *GitRepo* and based on its *paths* and *fleet.yaml* configurations it will deploy a *Bundle* resource in the `fleet-default` namespace. For more information, refer to Fleet's https://fleet.rancher.io/gitrepo-content[GitRepo Contents] documentation.

. `Fleet` then proceeds to deploy the `Kubernetes resources` from this *Bundle* to all the targeted `downstream clusters`. In the context of the `Kubernetes version upgrade`, Fleet deploys the following resources from the *Bundle* (depending on the Kubernetes distrubution):

.. `rke2-plan-agent`/`k3s-plan-agent` - instructs *SUC* on how to do a Kubernetes upgrade on cluster *_agent_* nodes. Will *not* be interpreted if the cluster consists only from _control-plane_ nodes.

.. `rke2-plan-control-plane`/`k3s-plan-control-plane` - instructs *SUC* on how to do a Kubernetes upgrade on cluster *_control-plane_* nodes.
+
[NOTE]
====
The above *SUC Plans* will be deployed in the `cattle-system` namespace of each downstream cluster.
====

. On the downstream cluster, *SUC* picks up the newly deployed *SUC Plans* and deploys an *_Update Pod_* on each node that matches the *node selector* defined in the *SUC Plan*.

. Depending on which *SUC Plans* you have deployed, the *Update Pod* will run either a https://hub.docker.com/r/rancher/rke2-upgrade/tags[rke2-upgrade] or a https://hub.docker.com/r/rancher/k3s-upgrade/tags[k3s-upgrade] image and will execute the following workflow on *each* cluster node:

.. https://kubernetes.io/docs/reference/kubectl/generated/kubectl_cordon/[Cordon] cluster node - to ensure that no pods are scheduled accidentally on this node while it is being upgraded, we mark it as `unschedulable`.

.. Replace the `rke2/k3s` binary that is installed on the node OS with the binary shipped by the `rke2-upgrade/k3s-upgrade` image that the Pod is currently running.

.. Kill the `rke2/k3s` process that is running on the node OS - this instructs the *supervisor* to automatically restart the `rke2/k3s` process using the new version.

.. https://kubernetes.io/docs/reference/kubectl/generated/kubectl_uncordon/[Uncordon] cluster node - after the successful Kubernetes distribution upgrade, the node is again marked as `scheduable`.
+
[NOTE]
====
For further information regarding how the `rke2-upgrade` and `k3s-upgrade` images work, see the https://github.com/rancher/rke2-upgrade[rke2-upgrade] and https://github.com/k3s-io/k3s-upgrade[k3s-upgrade] upstream projects.
====

With the above steps executed, the Kubernetes version of each cluster node should have been upgraded to the desired Edge compatible link:https://github.com/ipetrov117/fleet-examples/releases[release].

[#k8s-upgrade-suc-plan-deployment]
=== Kubernetes version upgrade - SUC Plan deployment

[#k8s-upgrade-suc-plan-deployment-git-repo]
==== SUC Plan deployment - GitRepo resource

A *GitRepo* resource, that ships the needed Kubernetes upgrade *SUC Plans*, can be deployed in one of the following ways:

. Through the `Rancher UI` - if you have a `Rancher` instance available in your environmnet.

. By manually deploying the *GitRepo* resource in the correct *Fleet* namespace - for environments that do not have a `Rancher` instance available.

Once deployed, to monitor the Kubernetes version upgrade process of the nodes of your targeted cluster, refer to the <<monitor_suc_plans>> documentation.

===== GitRepo creation - Rancher UI

. In the upper left corner, *☰ -> Continuous Delivery*

. Go to *Git Repos -> Add Repository*

If you use the `suse-edge/fleet-examples` repository: 

. *Repository URL* - `https://github.com/ipetrov117/fleet-examples.git`

. *Watch -> Revision* - choose a link:https://github.com/ipetrov117/fleet-examples/releases[release] tag for the `suse-edge/fleet-examples` repository that you wish to use

. Under *Paths* add the path to the Kubernetes distribution upgrade Fleets as seen in the release tag:

.. For RKE2 - `fleets/day2/system-upgrade-controller-plans/rke2-upgrade`

.. For K3s  - `fleets/day2/system-upgrade-controller-plans/k3s-upgrade`

. Select *Next* to move to the *target* configuration section. *Only select clusters for which you wish to upgrade the desired Kubernetes distribution*

. *Create*

Alternatively, if you decide to use your own repository to host these files, you would need to provide your repo data above.

===== GitRepo creation - manual

. Choose the desired Edge link:https://github.com/ipetrov117/fleet-examples/releases[release] tag that you wish to apply the Kubernetes *SUC upgrade Plans* from (referenced below as `$\{REVISION\}`).

. Pull the *GitRepo* resource:

** For *RKE2* clusters:
+
[,bash]
----
curl -o rke2-upgrade-gitrepo.yaml https://raw.githubusercontent.com/ipetrov117/fleet-examples/${REVISION}/gitrepos/day2/rke2-upgrade-gitrepo.yaml
----

** For *K3s* clusters:
+
[,bash]
----
curl -o k3s-upgrade-gitrepo.yaml https://raw.githubusercontent.com/ipetrov117/fleet-examples/${REVISION}/gitrepos/day2/k3s-upgrade-gitrepo.yaml
----

. Edit the *GitRepo* configuration, under `spec.targets` specify your desired target list. By default the `GitRepo` resources from the `suse-edge/fleet-examples` are *NOT* mapped to any down stream clusters.

** To match all clusters change the default `GitRepo` *target* to:
+
[, yaml]
----
spec:
  targets:
  - clusterSelector: {}
----

** Alternatively, if you want a more granular cluster selection see link:https://fleet.rancher.io/gitrepo-targets[Mapping to Downstream Clusters]


. Apply the *GitRepo* resources to your *Rancher Management Cluster*:
+
[,bash]
----
# RKE2
kubectl apply -f rke2-upgrade-gitrepo.yaml 

# K3s
kubectl apply -f k3s-upgrade-gitrepo.yaml
----

. View the created *GitRepo* resource under the `fleet-default` namespace:
+
[,bash]
----
# RKE2
kubectl get gitrepo rke2-upgrade -n fleet-default

# K3s
kubectl get gitrepo k3s-upgrade -n fleet-default

# Example output
NAME           REPO                                               COMMIT       BUNDLEDEPLOYMENTS-READY   STATUS
k3s-upgrade    https://github.com/ipetrov117/fleet-examples.git   edge-3.0.0   0/0                       
rke2-upgrade   https://github.com/ipetrov117/fleet-examples.git   edge-3.0.0   0/0                       
----

[#k8s-upgrade-suc-plan-deployment-bundle]
==== SUC Plan deployment - Bundle resource

A *Bundle* resource, that ships the needed Kubernetes upgrade *SUC Plans*, can be deployed in one of the following ways:

. Through the `Rancher UI` - if you have a `Rancher` instance available in your environmnet.

. By manually deploying the *Bundle* resource in the correct *Fleet* namespace - for environments that do not have a `Rancher` instance available.

Once deployed, to monitor the Kubernetes version upgrade process of the nodes of your targeted cluster, refer to the <<monitor_suc_plans>> documentation.

===== Bundle creation - Rancher UI

. In the upper left corner, click *☰ -> Continuous Delivery*

. Go to *Advanced* > *Bundles*

. Select *Create from YAML*

. From here you can create the Bundle in one of the following ways:

.. By manually copying the *Bundle* content to the *Create from YAML* page. Content can be retrieved:

... For RKE2 - https://raw.githubusercontent.com/ipetrov117/fleet-examples/$\{REVISION\}/bundles/day2/system-upgrade-controller-plans/rke2-upgrade/plan-bundle.yaml

... For K3s - https://raw.githubusercontent.com/ipetrov117/fleet-examples/$\{REVISION\}/bundles/day2/system-upgrade-controller-plans/k3s-upgrade/plan-bundle.yaml

.. By cloning the link:https://github.com/ipetrov117/fleet-examples.git[suse-edge/fleet-examples] repository to the desired link:https://github.com/ipetrov117/fleet-examples/releases[release] tag and selecting the *Read from File* option in the *Create from YAML* page. From there, navigate to the bundle that you need (`/bundles/day2/system-upgrade-controller-plans/rke2-upgrade/plan-bundle.yaml` for RKE2 and `/bundles/day2/system-upgrade-controller-plans/k3s-upgrade/plan-bundle.yaml` for K3s). This will auto-populate the *Create from YAML* page with the Bundle content

. Change the *target* clusters for the `Bundle`:

** To match all downstream clusters change the default Bundle `.spec.targets` to:
+
[, yaml]
----
spec:
  targets:
  - clusterSelector: {}
----

** For a more granular downstream cluster mappings, see link:https://fleet.rancher.io/gitrepo-targets[Mapping to Downstream Clusters].

. *Create*

===== Bundle creation - manual

. Choose the desired Edge link:https://github.com/ipetrov117/fleet-examples/releases[release] tag that you wish to apply the Kubernetes *SUC upgrade Plans* from (referenced below as `$\{REVISION\}`).

. Pull the *Bundle* resources:

** For *RKE2* clusters:
+
[,bash]
----
curl -o rke2-plan-bundle.yaml https://raw.githubusercontent.com/ipetrov117/fleet-examples/${REVISION}/bundles/day2/system-upgrade-controller-plans/rke2-upgrade/plan-bundle.yaml
----

** For *K3s* clusters:
+
[,bash]
----
curl -o k3s-plan-bundle.yaml https://raw.githubusercontent.com/ipetrov117/fleet-examples/${REVISION}/bundles/day2/system-upgrade-controller-plans/k3s-upgrade/plan-bundle.yaml
----

. Edit the `Bundle` *target* configurations, under `spec.targets` provide your desired target list. By default the `Bundle` resources from the `suse-edge/fleet-examples` are *NOT* mapped to any down stream clusters.

** To match all clusters change the default `Bundle` *target* to:
+
[, yaml]
----
spec:
  targets:
  - clusterSelector: {}
----

** Alternatively, if you want a more granular cluster selection see link:https://fleet.rancher.io/gitrepo-targets[Mapping to Downstream Clusters]


. Apply the *Bundle* resources to your *Rancher Management Cluster*:
+
[,bash]
----
# For RKE2
kubectl apply -f rke2-plan-bundle.yaml

# For K3s
kubectl apply -f k3s-plan-bundle.yaml
----

. View the created *Bundle* resource under the `fleet-default` namespace:
+
[,bash]
----
# For RKE2
kubectl get bundles rke2-upgrade -n fleet-default

# For K3s
kubectl get bundles k3s-upgrade -n fleet-default

# Example output
NAME           BUNDLEDEPLOYMENTS-READY   STATUS
k3s-upgrade    0/0                       
rke2-upgrade   0/0                       
----

[#k8s-upgrade-suc-plan-deployment-third-party]
==== SUC Plan deployment - third-party GitOps workflow

There might be use-cases where users would like to incorporate the Kubernetes upgrade resources to their own third-party GitOps workflow (e.g. `Flux`).

To get the upgrade resources that you need, first determine the he Edge link:https://github.com/ipetrov117/fleet-examples/releases[release] tag of the link:https://github.com/ipetrov117/fleet-examples.git[suse-edge/fleet-examples] repository that you would like to use.

After that, the resources can be found at:

* For a RKE2 cluster upgrade:

** For `control-plane` nodes - `fleets/day2/system-upgrade-controller-plans/rke2-upgrade/plan-control-plane.yaml`

** For `agent` nodes - `fleets/day2/system-upgrade-controller-plans/rke2-upgrade/plan-agent.yaml`

* For a K3s cluster upgrade:

** For `control-plane` nodes - `fleets/day2/system-upgrade-controller-plans/k3s-upgrade/plan-control-plane.yaml`

** For `agent` nodes - `fleets/day2/system-upgrade-controller-plans/k3s-upgrade/plan-agent.yaml`

[IMPORTANT]
====
These `Plan` resources are interpreted by the `system-upgrade-controller` and should be deployed on each downstream cluster that you wish to upgrade. For information on how to deploy the `system-upgrade-controller`, see <<third_party_git_ops>>.
====

To better understand how your GitOps workflow can be used to deploy the *SUC Plans* for Kubernetes version upgrade, it can be beneficial to take a look at the <<k8s-version-upgrade-overview,overview>> of the update procedure using `Fleet`.